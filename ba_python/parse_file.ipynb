{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT DEPENDENCIES 1\n",
    "import pandas\n",
    "import re\n",
    "\n",
    "from google.api_core.exceptions import InvalidArgument\n",
    "import google.generativeai as palm\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT DATA 2\n",
    "#open, read and store Data to variables\n",
    "#everything2.txt contains all data up to volume 32. Humanist.vol32.txt contains data of volume 32. \n",
    "with open('../assets/originalData/everything2.txt', 'r', encoding=\"cp437\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "with open('../assets/originalData/Humanist.vol32.txt', 'r', encoding=\"cp437\") as f:\n",
    "    text32 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPARE DATA 3\n",
    "#Concat variables\n",
    "text = text + text32\n",
    "#Creating list of Lines of \"text\"\n",
    "lines = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATTERN 4\n",
    "#Creating dict of diffent mail header types\n",
    "patterns = {\n",
    "    \"1\": [\n",
    "        r\"^\\s*From: (?P<data>.*)\",\n",
    "        r\"^\\s*Subject: (?P<data>.*)\",\n",
    "        r\"^\\s*Date: (?P<data>.*)\",\n",
    "        r\"^\\s*X-Humanist: (?P<data>.*)\"\n",
    "    ],\n",
    "    \"2\": [\n",
    "        r\"^\\s*From - (?P<sender>.*)\",\n",
    "        r\"^\\s*X-Mozilla-Status: (?P<data>.*)\",\n",
    "        r\"^\\s*X-Mozilla-Status2: (?P<data>.*)\",\n",
    "        r\"^\\s*Return-path: (?P<data>.*)\"\n",
    "    ],\n",
    "    \"3\": [\n",
    "        r\"^\\s*From (?P<data>.*)\",\n",
    "        r\"^\\s*Return-Path: (?P<data>.*)\",\n",
    "        r\"^\\s*X-Original-To: (?P<data>.*)\"\n",
    "    ],\n",
    "    \"4\": [\n",
    "        r\"^\\s*Return-Path: (?P<data>.*)\",\n",
    "        r\"^\\s*X-Original-To: (?P<data>.*)\",\n",
    "        r\"^\\s*Delivered-To: (?P<data>.*)\",\n",
    "        r\"^\\s*Received: (?P<data>.*)\"\n",
    "    ],\n",
    "    \"5\": [\n",
    "        r\"^\\s*Return-Path: (?P<data>.*)\",\n",
    "        r\"^\\s*X-Spam-Checker-Version: (?P<data>.*)\"\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATTERN KEY 5\n",
    "#Function to get the key of the current pattern\n",
    "def get_keys_from_value(patterns, val):\n",
    "    return [k for k, v in patterns.items() if v == val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HEADER LINES SUM 6\n",
    "#Function to get the header of the current mail as str\n",
    "def get_header_content_sum(start, header):\n",
    "    header_len = 0\n",
    "    header_content_sum = \"\"\n",
    "    header_content_current = \"\"\n",
    "    for i in range(start,len(lines)):\n",
    "        #Mail starts after 4 Lines of Header (if header == 1)\n",
    "        if (header[0] == 1):\n",
    "            if (header_len == 4):\n",
    "                header_len = i\n",
    "                return header_content_sum, header_len\n",
    "        #Mail starts with part of line \"Humanist Discussion Group, Vol. \"\n",
    "        if (\"Humanist Discussion Group, Vol. \" in lines[i]):\n",
    "            header_len = i\n",
    "            return header_content_sum, header_len\n",
    "        #Mail starts aftre \"Content-Transfer-Encoding: base64\"\n",
    "        if ((\"X-PPP-Vhost: \" in lines[i]) & (lines[i+1] == \"\") & (lines[i+4] == \"\") & (\"Humanist Discussion Group, Vol. \" not in lines[i+5]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+6]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+7])):\n",
    "            header_len = i\n",
    "            header_len = header_len + 5\n",
    "            return header_content_sum, header_len\n",
    "        #Mail starts after \"X-PPP-Vhost: digitalhumanities.org\"\n",
    "        if ((\"X-PPP-Vhost: \" in lines[i]) & (lines[i+1] == \"\") & (\"Humanist Discussion Group, Vol. \" not in lines[i+2]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+3]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+4]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+5]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+6])):\n",
    "            header_len = i\n",
    "            header_len = header_len + 2\n",
    "            return header_content_sum, header_len\n",
    "        #Mail starts after \"Errors-To: humanist-bounces@lists.digitalhumanities.org\"\n",
    "        if ((\"Errors-To: \" in lines[i]) & (lines[i+1] == \"\") & (\"Humanist Discussion Group, Vol. \" not in lines[i+2]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+3]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+4]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+5]) & (\"Humanist Discussion Group, Vol. \" not in lines[i+6])):\n",
    "            header_len = i\n",
    "            header_len = header_len + 2\n",
    "            return header_content_sum, header_len\n",
    "        header_len = header_len +1\n",
    "        header_content_current = lines[i]\n",
    "        if (header_content_sum == \"\"):\n",
    "            header_content_sum = header_content_current\n",
    "        else:\n",
    "            header_content_sum = header_content_sum + \"<br>\" + header_content_current\n",
    "        header_content_current = \"\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARSE 7\n",
    "#Parse through lines and adding parsed data to rows and collumns of lines_with_patters[]\n",
    "lines_with_patterns = []\n",
    "count = 0\n",
    "x_humanist = \"\"\n",
    "mail_content_sum = \"\"\n",
    "mail_content_current = \"\"\n",
    "#iterate through lines\n",
    "for i in range(len(lines)):\n",
    "        #iterate through pattern\n",
    "        for pattern in patterns.values():\n",
    "            window_length = len(pattern)\n",
    "            window = lines[i: i + window_length]\n",
    "            lines_patterns = zip(window, pattern)\n",
    "            matches = []\n",
    "            #iterate through lines_patterns\n",
    "            for l, p in lines_patterns:\n",
    "                m = re.match(p, l)\n",
    "                if m:\n",
    "                    matches.append(m.groupdict())\n",
    "            #check if match fits to pattern (header type)        \n",
    "            if len(matches) == len(pattern):\n",
    "                #Exclusion of recognizing pattern 3 and 4 for the same mail\n",
    "                if (\"From \" in lines[i-1]): \n",
    "                     continue\n",
    "                #Get key of the current mail pattern\n",
    "                keys = get_keys_from_value(patterns, pattern) \n",
    "                header = list(map(int, keys))\n",
    "                count = count +1\n",
    "\n",
    "                if header[0] == 1:\n",
    "                    content_header_sum, header_len = get_header_content_sum(i, header)\n",
    "                    lines_with_patterns.append( #Append a new row with current content to list\n",
    "                        {\n",
    "                            \"mailFrom\": lines[i],\n",
    "                            \"mailSubject\": lines[i+1],\n",
    "                            \"mailDate\": lines[i+2],\n",
    "                            \"mail_x-humanist\": lines[i+3],\n",
    "                            \"mailPattern\": keys,\n",
    "                            \"mailHeader_count\": count,\n",
    "                            \"mailHeader_content\": content_header_sum,\n",
    "                            \"mailContent\": mail_content_sum\n",
    "                        }\n",
    "                    )\n",
    "                    #Adding content to a specific position in the list\n",
    "                    if mail_content_sum != \"\":\n",
    "                         lines_with_patterns[count-2][\"mailContent\"] = mail_content_sum \n",
    "                         mail_content_sum = \"\"\n",
    "\n",
    "                if (header[0] == 2) | (header[0] == 3) | (header[0] == 4) | (header[0] == 5):\n",
    "                    content_header_sum, header_len = get_header_content_sum(i, header)\n",
    "                    if (header_len) < len(lines):\n",
    "                         x_humanist = lines[header_len]\n",
    "                    lines_with_patterns.append(\n",
    "                        {\n",
    "                            \"mail_x-humanist\": x_humanist,\n",
    "                            \"mailPattern\": keys,\n",
    "                            \"mailHeader_count\": count,\n",
    "                            \"mailHeader_content\": content_header_sum,\n",
    "                            \"mailContent\": mail_content_sum\n",
    "                        }\n",
    "                    )\n",
    "                    x_humanist = \"\"\n",
    "                    if mail_content_sum != \"\":\n",
    "                         lines_with_patterns[count-2][\"mailContent\"] = mail_content_sum\n",
    "                         mail_content_sum = \"\"\n",
    "\n",
    "        #Sum up the lines to capture the content of the current mail\n",
    "        if header_len <= i: \n",
    "            mail_content_current = lines[i]\n",
    "            if (mail_content_sum == \"\"):\n",
    "                mail_content_sum = mail_content_current\n",
    "            else:  \n",
    "                mail_content_sum = mail_content_sum + \"<br>\" + mail_content_current\n",
    "            mail_content_current = \"\"\n",
    "\n",
    "    \n",
    "        #Adding content to the last position in the list\n",
    "        if (i+1) == len(lines):\n",
    "            lines_with_patterns[count-1][\"mailContent\"] = mail_content_sum \n",
    "            mail_content_sum = \"\"\n",
    "            \n",
    "print(len(lines_with_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATAFRAME 8\n",
    "#Creating Dataframe\n",
    "dF = pandas.DataFrame(lines_with_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATAFRAME OPERATIONS 9\n",
    "#List entries containing NaN are replaced by an empty string\n",
    "dF.fillna('', inplace=True)\n",
    "#revise the columns of the DataFrame\n",
    "dF.loc[dF['mailDate'].isna() | (dF['mailDate'] == ''), 'mailDate'] = dF['mailContent'].str.extract(r\"Date: (.+?)<br>\", expand=False)\n",
    "dF[\"mailYear\"] = dF[\"mailDate\"].str.extract(r\"\\b(198[7-9]|199\\d|200\\d|201[0-8]|8[7-9]|9[0-9])\\b\", expand=False)\n",
    "#Specific parts of list entries are replaced by an empty string\n",
    "dF[\"mailFrom\"] = dF[\"mailFrom\"].replace(to_replace = \"From: \", value =\"\", regex = True) #\n",
    "dF[\"mailSubject\"] = dF[\"mailSubject\"].replace(to_replace = \"Subject: \", value =\"\", regex = True)\n",
    "dF[\"mailDate\"] = dF[\"mailDate\"].replace(to_replace = \"Date: \", value =\"\", regex = True)\n",
    "dF[\"mailContent\"] = dF[\"mailContent\"].replace(to_replace = \"<javascript:\", value =\"\", regex = True)\n",
    "dF[\"mail_x-humanist\"] = dF[\"mail_x-humanist\"].replace(to_replace = \"Humanist Discussion Group, \", value =\"\", regex = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMAT YEAR 10\n",
    "#Mail years are required.\n",
    "#before 2000 the year is partly represented only by the last two numbers\n",
    "#therefore iterate through the DataFrame and bring all years into the same format.\n",
    "#If no year is specified, it is set according to the previous mail.\n",
    "dF.fillna('', inplace=True)\n",
    "referenceYear = \"1987\"\n",
    "for i in range(len(dF)):\n",
    "    year = dF.loc[i][\"mailYear\"]\n",
    "    if (year == \"\"):\n",
    "        dF.loc[i, \"mailYear\"] = referenceYear\n",
    "    if (len(year) == 2):\n",
    "        year = '19' + year\n",
    "        referenceYear = year\n",
    "        dF.loc[i, \"mailYear\"] = year\n",
    "    if (len(year) == 4):\n",
    "        referenceYear = year\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIMEZONES 11\n",
    "#revise the columns of the DataFrame\n",
    "dF.loc[dF[\"mailDate\"].str.contains(r\"^<br>.*\", regex=True), [\"mailDate\"]] = \"\"\n",
    "dF.loc[dF['mailFrom'].isna() | (dF['mailFrom'] == ''), 'mailFrom'] = dF['mailContent'].str.extract(r\"<([^<>]*@[^<>]*)>\", expand=False)\n",
    "\n",
    "#operations to fill the mailTimeZone collumn with the same timezone format\n",
    "dF[\"mailTimeZone\"] = dF[\"mailDate\"].str.extract(r\"([+-]0\\d{3}|[+-]1[0-8]\\d{2})\", expand=False)\n",
    "dF.loc[dF['mailTimeZone'].isna() | (dF['mailTimeZone'] == ''), 'mailTimeZone'] = dF['mailDate'].str.extract(r\"\\b([A-Z]{3,4})\\b\", expand=False)\n",
    "dF.loc[dF['mailTimeZone'].isna() | (dF['mailTimeZone'] == ''), 'mailTimeZone'] = dF['mailDate'].str.extract(r\"\\b([a-z]{3,4})\\b\", expand=False)\n",
    "dF.fillna('', inplace=True)\n",
    "dF.loc[dF[\"mailTimeZone\"].str.contains(r\"JAN|FEB|MAR|APR|MAY|JUN|JUL|AUG|SEP|OCT|NOV|DEZ\", regex=True), [\"mailTimeZone\"]] = \"\"\n",
    "dF.loc[dF['mailTimeZone'].isna() | (dF['mailTimeZone'] == ''), 'mailTimeZone'] = dF['mailDate'].str.extract(r\"(?<=\\d{2}:\\d{2}\\s)([A-Za-z]{2,3})\", expand=False)\n",
    "\n",
    "timezone_mapping = {\n",
    "    'EST': '-0500',  # Eastern Standard Time\n",
    "    'est': '-0500',  # Eastern Standard Time\n",
    "    '-0500': '-0500',  # Eastern Standard Time\n",
    "    'EDT': '-0400',  # Eastern Daylight Time\n",
    "    'edt': '-0400',  # Eastern Daylight Time\n",
    "    '-0400': '-0400',  # Eastern Daylight Time\n",
    "    '+0400': '+0400', # Asia/Tehran\n",
    "    'CST': '-0600',  # Central Standard Time\n",
    "    'cst': '-0600',  # Central Standard Time\n",
    "    '-0600': '-0600',  # Central Standard Time\n",
    "    'CDT': '-0500',  # Central Daylight Time\n",
    "    'cdt': '-0500',  # Central Daylight Time\n",
    "    'MST': '-0700',  # Mountain Standard Time\n",
    "    'mst': '-0700',  # Mountain Standard Time\n",
    "    '-0700': '-0700',  # Mountain Standard Time\n",
    "    '+0700': '+0700', # Asia/Bangkok\n",
    "    'MDT': '-0600',  # Mountain Daylight Time\n",
    "    'mdt': '-0600',  # Mountain Daylight Time\n",
    "    'PST': '-0800',  # Pacific Standard Time\n",
    "    'pst': '-0800',  # Pacific Standard Time\n",
    "    '-0800': '-0800',  # Pacific Standard Time\n",
    "    'PDT': '-0700',  # Pacific Daylight Time\n",
    "    'pdt': '-0700',  # Pacific Daylight Time\n",
    "    'GMT': '+0000',  # Greenwich Mean Time\n",
    "    'gmt': '+0000',  # Greenwich Mean Time\n",
    "    '+0000': '+0000',  # Greenwich Mean Time\n",
    "    '-0000': '-0000',\n",
    "    'UTC': '+0000',   # Coordinated Universal Time\n",
    "    'utc': '+0000',   # Coordinated Universal Time\n",
    "    'AST': '-0400',  # Atlantic Standard Time\n",
    "    'ast': '-0400',  # Atlantic Standard Time\n",
    "    'ADT': '-0300',  # Atlantic Daylight Time\n",
    "    'adt': '-0300',  # Atlantic Daylight Time\n",
    "    '-0300': '-0300',  # Atlantic Daylight Time\n",
    "    'NST': '-0330',  # Newfoundland Standard Time\n",
    "    'nst': '-0330',  # Newfoundland Standard Time\n",
    "    '-0330': '-0330',  # Newfoundland Standard Time\n",
    "    'NDT': '-0230',  # Newfoundland Daylight Time\n",
    "    'ndt': '-0230',  # Newfoundland Daylight Time\n",
    "    '-0230': '-0230',  # Newfoundland Daylight Time\n",
    "    'AKST': '-0900',  # Alaska Standard Time\n",
    "    'akst': '-0900',  # Alaska Standard Time\n",
    "    '-0900': '-0900',  # Alaska Standard Time\n",
    "    'AKDT': '-0800',  # Alaska Daylight Time\n",
    "    'akdt': '-0800',  # Alaska Daylight Time\n",
    "    'HST': '-1000',  # Hawaii Standard Time\n",
    "    'hst': '-1000',  # Hawaii Standard Time\n",
    "    '-1000': '-1000',  # Hawaii Standard Time\n",
    "    'HDT': '-0900',  # Hawaii Daylight Time\n",
    "    'hdt': '-0900',  # Hawaii Daylight Time\n",
    "    'EMT': '+0100',\n",
    "    'emt': '+0100',\n",
    "    'BST': '+0100',  # British Summer Time\n",
    "    'bst': '+0100',\n",
    "    '+0100': '+0100',\n",
    "    'BDT': '+0600',\n",
    "    'bdt': '+0600',\n",
    "    '+0600': '+0600',\n",
    "    'IST': '+0530',  # Indian Standard Time\n",
    "    'ist': '+0530',\n",
    "    '+0530': '+0530',\n",
    "    'CET': '+0100',  # Central European Time\n",
    "    'cet': '+0100',\n",
    "    'ITA': '+0200',\n",
    "    'ita': '+0200',\n",
    "    'MEZ': '+0200',\n",
    "    'mez': '+0200', \n",
    "    'CEST': '+0200',  # Central European Summer Time\n",
    "    'cest': '+0200',\n",
    "    'EET': '+0200',  # Eastern European Time\n",
    "    'eet': '+0200',\n",
    "    '+0200': '+0200',\n",
    "    '-0200': '-0200', #America/SaoPaulo\n",
    "    'EEST': '+0300',  # Eastern European Summer Time\n",
    "    'eest': '+0300',\n",
    "    '+0300': '+0300',\n",
    "    'JST': '+0900',  # Japan Standard Time\n",
    "    'jst': '+0900',\n",
    "    'KST': '+0900',  # Korea Standard Time\n",
    "    'kst': '+0900',\n",
    "    '+0900': '+0900',\n",
    "    'AEST': '+1000',  # Australian Eastern Standard Time\n",
    "    'aest': '+1000',\n",
    "    '+1000': '+1000',\n",
    "    'AEDT': '+1100',  # Australian Eastern Daylight Time\n",
    "    'aedt': '+1100',\n",
    "    '+1100': '+1100',\n",
    "    'NZST': '+1200',  # New Zealand Standard Time\n",
    "    'nzst': '+1200',\n",
    "    '+1200': '+1200',\n",
    "    'NZDT': '+1300',  # New Zealand Daylight Time\n",
    "    'nzdt': '+1300',\n",
    "    '+1300': '+1300',\n",
    "    'MSK': '+0300',  # Moscow Time\n",
    "    'msk': '+0300',\n",
    "    'SGT': '+0800',  # Singapore Time\n",
    "    'sgt': '+0800',\n",
    "    'AWST': '+0800',  # Australian Western Standard Time\n",
    "    'awst': '+0800',\n",
    "    '+0800': '+0800',\n",
    "    'ACST': '+0930',  # Australian Central Standard Time\n",
    "    'acst': '+0930',\n",
    "    '+0930': '+0930',\n",
    "    'ACDT': '+1030',  # Australian Central Daylight Time\n",
    "    'acdt': '+1030',\n",
    "    '+1030': '+1030',\n",
    "    'WAT': '+0100',  # West Africa Time\n",
    "    'wat': '+0100',\n",
    "    'CAT': '+0200',  # Central Africa Time\n",
    "    'cat': '+0200',\n",
    "    'SAST': '+0200',  # South African Standard Time\n",
    "    'sast': '+0200',\n",
    "    'FJT': '+1200',  # Fiji Time\n",
    "    'fjt': '+1200',\n",
    "    'LKT': '+0530',  # Sri Lanka Time\n",
    "    'lkt': '+0530',\n",
    "    'MVT': '+0500',  # Maldives Time\n",
    "    'mvt': '+0500',\n",
    "    '+0500': '+0500',\n",
    "    'PHT': '+0800',  # Philippine Time\n",
    "    'pht': '+0800',\n",
    "    'IRKT': '+0800',  # Irkutsk Time\n",
    "    'irkt': '+0800',\n",
    "    'ULAT': '+0800',  # Ulaanbaatar Time\n",
    "    'ulat': '+0800',\n",
    "    'VET': '-0430',  # Venezuelan Standard Time\n",
    "    'vet': '-0430',\n",
    "    '-0430': '-0430',\n",
    "    'CLT': '-0300',  # Chile Standard Time\n",
    "    'clt': '-0300',\n",
    "    'CLST': '-0300',  # Chile Summer Time\n",
    "    'clst': '-0300',\n",
    "    'ART': '-0300',  # Argentina Time\n",
    "    'art': '-0300'\n",
    "}\n",
    "\n",
    "dF['mailTimeZone'] = dF['mailTimeZone'].map(timezone_mapping)\n",
    "\n",
    "#fill the mailVolume collumn with the same format\n",
    "dF[\"mailVolume\"] = dF[\"mail_x-humanist\"].str.extract(r\"(Vol\\. \\d{1,2})\", expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTI 12\n",
    "#Search for multiple mails in mail_content and mark them with Y\n",
    "dF.loc[dF[\"mailContent\"].str.contains(r\"\\(1\\) ---+\", regex=True), [\"mailMultiple\"]] = \"Y\"\n",
    "dF.loc[dF[\"mailContent\"].str.contains(r\"\\(1\\)---+\", regex=True), [\"mailMultiple\"]] = \"Y\"\n",
    "dF.loc[dF[\"mailContent\"].str.contains(r\"\\[1\\]---+\", regex=True), [\"mailMultiple\"]] = \"Y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM 13\n",
    "#using Palm API to categorize mailContent into predefined categories \n",
    "\n",
    "#private API Key\n",
    "palm.configure(api_key=config.API_KEY)\n",
    "\n",
    "#model = text-bison-001\n",
    "models = [m for m in palm.list_models() if 'generateText' in m.supported_generation_methods]\n",
    "model = models[0].name\n",
    "\n",
    "#iterate through DataFrame\n",
    "for i in range(0, len(dF), 1):    \n",
    "    prompt = \"Categorize the email based on its content into the following categories. Multiple categories can be assigned to the mail: Conference Announcements, Book Announcements, Calls for Papers, Job Postings, Research Queries, Event Information, Publications, Technical Issues, Literature Review, Data Sharing, Collaboration Requests, Research Findings, Methodological Discussions, Workshop Invitations, Seminar Details, Webinar Information, Symposium Notices, Journal Articles, Online Resources, Databases. Email content: \" + dF.loc[i][\"mailContent\"]\n",
    "\n",
    "    #try and except to cach specific error\n",
    "    try:\n",
    "        completion = palm.generate_text(\n",
    "            model=model,\n",
    "            prompt=prompt,\n",
    "            temperature=0,\n",
    "            max_output_tokens=800,\n",
    "        )\n",
    "        #append result to mailContentCategory\n",
    "        dF.loc[i, \"mailContentCategory\"] = completion.result\n",
    "    except InvalidArgument as e:\n",
    "        print(f\"Fehler bei E-Mail-Index {i}: {e}. Überspringe diese E-Mail.\")\n",
    "        dF.loc[i, \"mailContentCategory\"] = \"Unsupported Language\"\n",
    "    except Exception as e:\n",
    "        print(f\"Ein unerwarteter Fehler trat auf bei E-Mail-Index {i}: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT 14\n",
    "#creating second Dataframe and save Data created with palm\n",
    "#dF2 = pandas.DataFrame\n",
    "#dF2.to_csv('batest43.csv')\n",
    "\n",
    "#read stored data and hand over mailContentCategory to actual DataFrame\n",
    "#dF2 = pandas.read_csv('batest43.csv')\n",
    "#dF['mailContentCategory'] = dF2['mailContentCategory']\n",
    "\n",
    "#drop the collumns mailPattern and mailHeader_count wichare no longer in use\n",
    "cols = ['mailPattern', 'mailHeader_count']\n",
    "dF.drop(cols, inplace=True, axis = 1)\n",
    "\n",
    "#ouput final CSV-file -> later used as import to database table\n",
    "dF.to_csv('HumanistReaserchDataFinal.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
